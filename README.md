# HYPER (brain decoding framework) ðŸ§  + ðŸ¤– + ðŸ“– = âœ¨ 

This repo accompanies the original paper "Hyperrealistic neural decoding: Reconstructing faces from fMRI activations via the GAN latent space" ([Dado et al., 2020 (biorxiv)](https://www.biorxiv.org/content/10.1101/2020.07.01.168849v3)). This study introduces a novel experimental paradigm that uses synthesized yet highly naturalistic stimuli with a priori known feature representations together with an implementation thereof for HYperrealistic reconstruction of PERception (HYPER) of face images from brain recordings. The goal was to reveal what information was present in the recorded brain responses by reconstructing the original face stimuli presented to the participants.

## The experiment

Two participants were looking at images of faces while we recorded their brain responses in the MRI scanner. After that, we trained a model to reconstruct what the participants were seeing from their fMRI recordings **alone**. 

Results were ground-breaking: 
<br/>
<br/>
<br/>

![](https://github.com/Neural-Coding/HYPER/blob/master/images/small.png)

## The trick

The faces in the presented photographs **do not really exist**, but are artificially generated by a progressiveGAN ([PGGAN](https://github.com/tkarras/progressive_growing_of_gans)) from latent vectors. As it turns out, the PGGAN latent space and the neural face manifold have an approximate linear relationship that can be exploited during brain decoding. That is, the latent vectors used for face generation effectively capture the same defining stimulus features as the fMRI measurements. As such, we can predict the latents that underlie the perceived face images and feed them to the PGGAN for (re)generation, leading to the most accurate reconstructions of perception to date.

ðŸ¤–ðŸ¤–ðŸ¤–



## Required components

This repo contains (demo) code in Jupyter Notebooks to present the approach. All required data to reproduce the results are made available. 

* Python 3.6
* Python libraries: chainer, cupy, tensorflow, keras, keras-vggface, skimage, sklearn, scipy, numpy, matplotlib, PIL, os, math, pickle
* [Models (Google Drive)](https://drive.google.com/drive/u/1/folders/1OW0cfnoP8_tZBGWLbpiPPX81QH9pusjv)
* [Preprocessed dataset (Google Drive)](https://drive.google.com/drive/u/1/folders/1xmlusRDS3bTsB78_7RA__RUYyCcAS1jF)
* [PGGAN model for face generation (Github)](https://drive.google.com/drive/folders/15hvzxt_XxuokSmj0uO4xxMTMWVc0cIMU)
* [System requirements for PGGAN (Github)](https://github.com/tkarras/progressive_growing_of_gans)
(incl. [this tfutil library](https://raw.githubusercontent.com/tkarras/progressive_growing_of_gans/master/tfutil.py))
* [5 decision boundaries (Github)](https://github.com/genforce/interfacegan/tree/master/boundaries) disentangled by conditional manipulation

Preprocessing of the fMRI measurements (step 1), creating the final dataset of latents and brain data (step 2), test stimuli and reconstructions can be found on [Google Drive](https://drive.google.com/drive/u/1/folders/1NEblHtlRFvUyD5CA2sqSVfcGlfJBqw_T).


## A look into the future ðŸš€

For the first time, we have exploited the latent space of a generative model in neural decoding during perception of synthetic face photographs. It should however be noted that the results of this study are still valid reconstructions of visual perception regardless of the nature of the stimuli themselves. Considering the speed of progress in the field of generative modeling, this framework will likely result in even more impressive reconstructions of perception. 

The sky is the limit.


